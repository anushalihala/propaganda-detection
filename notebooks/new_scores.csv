,desc,model_checkpoint,train_acc,train_f1,train_precision,train_recall,valid_acc,valid_f1,valid_precision,valid_recall
0,"(model 10 with spacy tokens) 64u BLSTM layer, batchnorm, 0.2 dropout, 2u BLSTM layer return seq, batchnorm, flatten, 1 dense. Pos Threshold=0.5. Trainable embeddings. 5 epochs",1553766134,0.9938876154754462,0.9727722772277227,0.9650092081031308,0.9806612601372426,0.9615224336713432,0.8301655426118946,0.8296568627450981,0.8306748466257668
1,"(model 10 with spacy tokens and vader sentiment) 64u BLSTM layer, batchnorm, 0.2 dropout, 2u BLSTM layer return seq, batchnorm, flatten, sentiment features concatenation, 1 dense. Pos Threshold=0.5. Trainable embeddings. 3 epochs with early stopping",1553771492,0.9486004028617072,0.7172334734428736,0.9255424063116372,0.5854647535870243,0.9342964300597304,0.6290196078431372,0.8717391304347826,0.4920245398773006
2,"(model 10 with spacy tokens and vader sentiment) 64u BLSTM layer, batchnorm, 0.2 dropout, 2u BLSTM layer return seq, batchnorm, flatten, sentiment features concatenation, 1 dense. Pos Threshold=0.3. Trainable embeddings. 3 epochs with early stopping",1553771492,0.9557894005695632,0.7844929744371085,0.8578304331728991,0.7227074235807859,0.9395749409640228,0.7030716723549488,0.7923076923076923,0.6319018404907976
3,"(model 10 with spacy tokens and vader sentiment) 64u BLSTM layer, batchnorm, 0.2 dropout, 2u BLSTM layer return seq, batchnorm, flatten, dense32 sentiment features concatenation, 1 dense. Pos Threshold=0.3. Trainable embeddings. 5? epochs with early stopping",1553775435,0.9817323053413906,0.9129139072847682,0.9728299223712068,0.8599500935745478,0.9502708709542992,0.7475317348377998,0.8789386401326701,0.6503067484662577
4,"(model 10 with spacy tokens and vader sentiment) 64u BLSTM layer, batchnorm, 0.2 dropout, 2u BLSTM layer return seq, batchnorm, flatten | dense64, sentiment features concatenation | 32 dense, 1 dense. Pos Threshold=0.4. Trainable embeddings. 4 epochs with early stopping",1553775435,0.9953809821490588,0.9794467624787514,0.9705972434915774,0.988459139114161,0.956243922767051,0.8080438756855576,0.8026634382566586,0.8134969325153374
